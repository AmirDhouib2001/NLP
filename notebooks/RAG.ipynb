{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53a43b03-efe3-498d-8463-9ae52c425912",
   "metadata": {},
   "source": [
    "# TD: RAG\n",
    "\n",
    "Dans ce notebook, un RAG basique est implémenté:\n",
    "- On chunk les documents par paragraphes\n",
    "- On a un embedding pour les chunks\n",
    "- Pour une question, on peut embedde la question et récupérer les N chunks les plus pertinents\n",
    "- On utilise un modèle de génération de texte (SMoLL) pour faire la partie question + chunks les plus pertinents -> réponse.\n",
    "\n",
    "Téléchargez (cette archive)[https://drive.google.com/file/d/1TnfKs7bTwmpbXklbgiIBpdw7I_wJ5y9Y/view?usp=sharing] avec différentes \n",
    "\n",
    "Dans ce TD, vous allez expérimenter différentes façons de chunk et d'embeded les documents et les questions pour que le RAG retrieve les documents les plus pertinents. <br/>\n",
    "Vous expérimenterez aussi la prompt donnée au générateur de texte pour avoir les meilleures réponses.\n",
    "\n",
    "Voici la [liste de questions](https://drive.google.com/file/d/14hZ0hTx5dM1WgJYewZsn9BkHzEReq-pj/view?usp=sharing) que je poserai au RAG. </br>\n",
    "A rendre: \n",
    "- Le notebook de votre RAG\n",
    "- un CSV avec question,embedding,rag_reply\n",
    "- un CSV avec chunk,embedding</br>\n",
    "L'embedding doit être le JSON d'une liste de float.</br>\n",
    "Quand je ferai \"json.loads(embedding)\", je dois récupérer une liste de floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "349cd335-0b3d-45cd-873f-3890d85413a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0747a5ba-a9b7-4932-a254-7d05f4c412ab",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "824ec18e-fdad-4093-a9bd-7b226d14942a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"../data/raw/rag/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "37fe1e46-e7ba-42d4-af4a-72f19ee39548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Title: Introduction to Cybersecurity: Principles and Practices  \\n\\n**Teacher:** Professor Lydia Carter  \\n\\n**Description:**  \\nThis course introduces the fundamentals of cybersecurity, focusing on protecting systems, networks, and data from cyber threats. Students will explore key topics such as cryptography, network security, ethical hacking, and risk management. Through practical labs and real-world case studies, students will gain hands-on experience in identifying vulnerabilities, implementing security measures, and understanding the legal and ethical aspects of cybersecurity.  \\n\\n**Prerequisites:**  \\n- Basic knowledge of computer networks and operating systems  \\n- Proficiency in at least one programming language (e.g., Python, Java, or C++)  \\n- Completion of \"Introduction to Computer Science\" or equivalent  \\n\\n**Assessment:**  \\n- Weekly quizzes and assignments (25%)  \\n- Midterm exam: Fundamentals of cybersecurity (20%)  \\n- Final project: Design and present a comprehensive security solution (35%)  \\n- Participation in lab exercises and discussions (20%)  \\n\\n**Schedule Time:**  \\n- Mondays and Wednesdays: 1:30 PM - 3:00 PM  \\n- Lab Sessions: Fridays 2:00 PM - 4:00 PM  \\n\\n**Course Outline:**  \\n1. **Introduction to Cybersecurity**  \\n   - Understanding cyber threats and attack vectors  \\n   - Overview of cybersecurity principles: confidentiality, integrity, and availability  \\n\\n2. **Cryptography Basics**  \\n   - Symmetric and asymmetric encryption  \\n   - Hashing and digital signatures  \\n\\n3. **Network Security**  \\n   - Firewalls, intrusion detection systems, and VPNs  \\n   - Securing wireless and wired networks  \\n\\n4. **Application Security**  \\n   - Common vulnerabilities: SQL injection, XSS, and CSRF  \\n   - Secure coding practices and vulnerability scanning  \\n\\n5. **Ethical Hacking and Penetration Testing**  \\n   - Reconnaissance and vulnerability assessment  \\n   - Exploitation techniques and report writing  \\n\\n6. **Risk Management and Incident Response**  \\n   - Conducting risk assessments and developing mitigation strategies  \\n   - Incident detection, response, and recovery  \\n\\n7. **Legal and Ethical Issues in Cybersecurity**  \\n   - Understanding cybersecurity laws and regulations  \\n   - Ethical dilemmas and professional responsibilities  \\n\\n8. **Final Project**  \\n   - Analyze a case study or design a security solution for a simulated organization  \\n   - Present findings and recommendations in a detailed report and class presentation  \\n\\nThis course equips students with the foundational knowledge and practical skills needed to pursue careers in cybersecurity and effectively safeguard digital assets in a rapidly evolving threat landscape.\\n'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = []\n",
    "for filename in path.glob(\"*.md\"):\n",
    "    with open(filename) as f:\n",
    "        texts.append(f.read())\n",
    "\n",
    "texts[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66344eb7-0679-4ea5-aa1b-ee3c84f8c98c",
   "metadata": {},
   "source": [
    "# Chunk\n",
    "## Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3dd5aee6-83de-4d1a-a0bf-15a28cf3cc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_class(text):\n",
    "    chunks = text.split(\"\\n\\n\")\n",
    "    title = chunks[0].replace(\"# Title: \", \"\")\n",
    "    return {\"title\": title, \"chunks\": chunks}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a9c937dc-674f-4ff7-8a76-b87d2d23c675",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_class_add_title(text):\n",
    "    chunks = text.split(\"\\n\\n\")\n",
    "    title = chunks[0].replace(\"# Title: \", \"\")\n",
    "    return {\"title\": title, \"chunks\": [f\"{title}: {chunk}\" for chunk in chunks]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "519b2380-54b3-44b1-a3fd-27f97a324c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = sum((parse_class_add_title(txt)[\"chunks\"] for txt in texts), [])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104688fd-ef0e-469b-bd08-c435dd4ebdea",
   "metadata": {},
   "source": [
    "# Embedding\n",
    "\n",
    "## BAAI's embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6546cc1c-b08e-4a84-9439-db52f6b3b281",
   "metadata": {},
   "outputs": [],
   "source": [
    "from FlagEmbedding import FlagModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8778ce83-5d6b-48d7-8871-a90316414699",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FlagModel(\n",
    "    'BAAI/bge-base-en-v1.5',\n",
    "    query_instruction_for_retrieval=\"Represent this sentence for searching relevant passages:\",\n",
    "    use_fp16=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e6ac8413-e373-4d6e-adec-dc62113f36ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "corpus_embedding = model.encode(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "16e8c758-b27e-4779-b9e4-4c075927547d",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "    \"Who is the reinforcement learning teacher?\",\n",
    "    \"In what class will I learn game AI?\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "03f7c1c3-127a-47d9-a49f-18dab8968d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_embedding = model.encode(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "df3150b5-63fa-4b07-a9c7-66ef56c4ebb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_scores = query_embedding @ corpus_embedding.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d6d0738f-cefc-458b-aaa5-2a096e4fc739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ---- \n",
      "Query:  Who is the reinforcement learning teacher?\n",
      "Sources:\n",
      "1 -- similarity 0.80 -- \" Foundations of Reinforcement Learning  : **Teacher:** Dr. Arjun Patel   \"\n",
      "2 -- similarity 0.74 -- \" Foundations of Reinforcement Learning  : # Title: Foundations of Reinforcement Learning   \"\n",
      "3 -- similarity 0.71 -- \" Foundations of Reinforcement Learning  : 2. **Tabular Methods**  \n",
      "   - Dynamic programming approaches: Policy Iteration and Value Iteration  \n",
      "   - Monte Carlo methods and Temporal-Difference (TD) Learning   \"\n",
      "4 -- similarity 0.71 -- \" Foundations of Reinforcement Learning  : 4. **Policy-Based Methods**  \n",
      "   - Policy Gradient methods and REINFORCE algorithm  \n",
      "   - Advantage Actor-Critic (A2C) and Proximal Policy Optimization (PPO)   \"\n",
      "5 -- similarity 0.71 -- \" Foundations of Reinforcement Learning  : **Description:**  \n",
      "This course explores the foundational principles and practical applications of reinforcement learning (RL), a branch of machine learning focused on decision-making and sequential problem-solving. Students will learn about key RL algorithms, such as Q-Learning, Deep Q-Networks (DQN), Policy Gradient methods, and Actor-Critic models. Through coding assignments and projects, students will gain hands-on experience building RL agents to tackle challenges like game playing, robotics, and resource optimization. \"\n",
      " ---- \n",
      "Query:  In what class will I learn game AI?\n",
      "Sources:\n",
      "1 -- similarity 0.67 -- \" Foundations of Reinforcement Learning  : 6. **Applications of RL**  \n",
      "   - Game-playing agents (e.g., OpenAI Gym environments)  \n",
      "   - Autonomous decision-making in robotics and operations research   \"\n",
      "2 -- similarity 0.67 -- \" Foundations of Reinforcement Learning  : **Description:**  \n",
      "This course explores the foundational principles and practical applications of reinforcement learning (RL), a branch of machine learning focused on decision-making and sequential problem-solving. Students will learn about key RL algorithms, such as Q-Learning, Deep Q-Networks (DQN), Policy Gradient methods, and Actor-Critic models. Through coding assignments and projects, students will gain hands-on experience building RL agents to tackle challenges like game playing, robotics, and resource optimization. \"\n",
      "3 -- similarity 0.65 -- \" Foundations of Reinforcement Learning  : This course provides a solid foundation in reinforcement learning, equipping students with the skills to design intelligent systems capable of learning and adapting to complex environments.\n",
      " \"\n",
      "4 -- similarity 0.65 -- \" Foundations of Reinforcement Learning  : **Prerequisites:**  \n",
      "- Strong programming skills in Python  \n",
      "- Basic understanding of linear algebra, probability, and calculus  \n",
      "- Completion of \"Introduction to Machine Learning\" or equivalent  \n",
      "- Familiarity with deep learning concepts (preferred but not mandatory)   \"\n",
      "5 -- similarity 0.64 -- \" Foundations of Reinforcement Learning  : **Teacher:** Dr. Arjun Patel   \"\n"
     ]
    }
   ],
   "source": [
    "for query, score in zip(queries, sim_scores):\n",
    "    print(\" ---- \")\n",
    "    print(\"Query: \", query)\n",
    "    indexes = np.argsort(score)[-5:]\n",
    "    print(\"Sources:\")\n",
    "    for i, idx in enumerate(reversed(indexes)):\n",
    "        if score[idx] > .5:\n",
    "            print(f\"{i+1} -- similarity {score[idx]:.2f} -- \\\"\", chunks[idx], '\"')\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186611b2-d128-4884-9bec-a6935715e371",
   "metadata": {},
   "source": [
    "# Eval retrieval: Mean Reciprocal Rank\n",
    "Le fichier [question_answer_short.csv](https://drive.google.com/file/d/1EB8IwGlqvpNy3oq7xyR2IzdqJDX8C_fr/view?usp=drive_link) contient une liste de question et le texte à retrouver dans les documents.<br/>\n",
    "Je considère que tout chunk contenant le \"texte à retrouver\" était un bon chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8fd74624-9c0b-4480-b572-02cae5e84dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path / \"question_answer_short.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2bb81d11-888f-400e-b811-54ef53da5d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_embedding = model.encode(list(df[\"question\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "136a9728-1a69-433a-b425-887de3b6f556",
   "metadata": {},
   "outputs": [],
   "source": [
    "acceptable_chunks = []\n",
    "for answer in df[\"answer\"]:\n",
    "    chunks_ok = set(i for i, chunk in enumerate(chunks) if answer in chunk)\n",
    "    acceptable_chunks.append(chunks_ok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "31efd406-3209-4714-a1a9-ed4c291d614a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mrr(sim_score, acceptable_chunks):\n",
    "    ranks = []\n",
    "    for this_score, this_acceptable_chunks in zip(sim_score, acceptable_chunks):\n",
    "        indexes = reversed(np.argsort(this_score))\n",
    "        rank = 1 + next(i for i, idx in enumerate(indexes) if idx in this_acceptable_chunks)\n",
    "        ranks.append(rank)\n",
    "        \n",
    "    return {\n",
    "        \"score\": sum(1 / r if r < 6 else 0 for r in ranks) / len(ranks),\n",
    "        \"ranks\": ranks,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bf24857a-ee28-42d7-8e14-9a16db07a9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_scores = query_embedding @ corpus_embedding.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1d1929a6-6d5c-4c26-9c05-3a2ca2d461f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = compute_mrr(sim_scores, acceptable_chunks)\n",
    "res[\"score\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549268e7-8bf9-47a5-b9ac-64decbb88fa5",
   "metadata": {},
   "source": [
    "# Text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "40a534b4-8011-46d8-9a56-6f4ed10c22d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_context(query, corpus, corpus_embeddings):\n",
    "    query_embedding = model.encode([query])\n",
    "    sim_scores = query_embedding @ corpus_embedding.T\n",
    "    indexes = list(np.argsort(sim_scores[0]))[-5:]\n",
    "    return [corpus[i] for i in indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fb22e930-351f-450a-80a7-72dfa9f721a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['# Natural Language Processing (NLP) Fundamentals and Applications: 5. **Applications of NLP**\\n  - Sentiment analysis and text classification\\n  - Machine translation and summarization\\n  - Chatbots and conversational agents',\n",
       " '# Natural Language Processing (NLP) Fundamentals and Applications: **Description:**\\nThis course offers a comprehensive introduction to the field of Natural Language Processing (NLP), focusing on the computational techniques that allow machines to understand, interpret, and generate human language. You will learn about linguistic structures, text preprocessing, sentiment analysis, machine translation, and language modeling. Using hands-on projects and industry-relevant tools, this course provides a strong foundation in both traditional and modern NLP methods, including neural networks and transformers.',\n",
       " '# Natural Language Processing (NLP) Fundamentals and Applications: Whether you aim to pursue a career in AI or enhance your programming toolkit, this course equips you with the skills to tackle real-world problems in language understanding and generation.\\n',\n",
       " '# Natural Language Processing (NLP) Fundamentals and Applications: **Teacher:** Dr. Evelyn Chang',\n",
       " '# Natural Language Processing (NLP) Fundamentals and Applications: 6. **Final Project**\\n  - Design and implement a real-world NLP application, such as a sentiment analyzer, chatbot, or language translator\\n  - Present findings through a written report and class presentation']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_context(\"Which class will teach me to build a chatbot?\", chunks, corpus_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9181f90f-c7e0-450f-bb87-f2002c061107",
   "metadata": {},
   "source": [
    "## SMOLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1de9b848-78ea-4cc3-9aa4-88732d871b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "checkpoint = \"HuggingFaceTB/SmolLM2-360M-Instruct\"\n",
    "# checkpoint = \"HuggingFaceTB/SmolLM2-1.7B-Instruct\"\n",
    "# checkpoint = \"amd/Instella-3B\"\n",
    "\n",
    "device = \"cpu\" # for GPU usage or \"cpu\" for CPU usage\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model_generator = AutoModelForCausalLM.from_pretrained(checkpoint).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5edd1fc8-d9f6-4c55-a2f9-2f2952280471",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_smoll_prompt(query, corpus, corpus_embedding):\n",
    "    context_str = \"\\n\\n\".join(get_context(query, chunks, corpus_embedding))\n",
    "\n",
    "    prompt = f\"\"\"<|im_start|>system\n",
    "You reply to the user's request using only context information.\n",
    "Context information to answer \"{query}\" is below\n",
    "------\n",
    "Context:\n",
    "{context_str}\n",
    "------\n",
    "You are a helpful assistant for a Computer Science university. You reply to students'questions about the courses that they can attend.\n",
    "<|im_end|>\n",
    "<|im_start|>user\n",
    "{query}\n",
    "<|im_reend|>\n",
    "\"\"\"\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5c837fad-d2a8-44bf-b091-7dac08ee36ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_smoll_messages(query, chunks, corpus_embedding):\n",
    "    context_str = \"\\n\\n\".join(get_context(query, chunks, corpus_embedding))\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": f\"\"\"You reply to the user's request using only context information.\n",
    "Context information to answer \"{query}\" is below\n",
    "------\n",
    "Context:\n",
    "{context_str}\n",
    "------\n",
    "You are a helpful assistant for a Computer Science university. You reply to students'questions about the courses that they can attend.\n",
    "\"\"\"},\n",
    "        {\"role\": \"user\", \"content\": query},\n",
    "    ]\n",
    "\n",
    "    return messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "aba8291c-c285-4711-bb9c-f0d5b771b49f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You reply to the user's request using only context information.\n",
      "Context information to answer \"Who is the NLP teacher?\" is below\n",
      "------\n",
      "Context:\n",
      "# Natural Language Processing (NLP) Fundamentals and Applications: **Prerequisites:**\n",
      "- Proficiency in Python programming\n",
      "- Basic understanding of linear algebra and probability\n",
      "- Successful completion of \"Introduction to Machine Learning\" or equivalent\n",
      "\n",
      "# Natural Language Processing (NLP) Fundamentals and Applications: **Course Outline:**\n",
      "1. **Introduction to NLP**\n",
      "  - Key concepts and challenges\n",
      "  - Overview of linguistic structure and grammar\n",
      "\n",
      "# Natural Language Processing (NLP) Fundamentals and Applications: # Natural Language Processing (NLP) Fundamentals and Applications\n",
      "\n",
      "# Natural Language Processing (NLP) Fundamentals and Applications: **Schedule Time:**\n",
      "- Tuesdays and Thursdays: 10:00 AM - 11:30 AM\n",
      "- Lab Sessions: Fridays 2:00 PM - 4:00 PM\n",
      "\n",
      "# Natural Language Processing (NLP) Fundamentals and Applications: **Teacher:** Dr. Evelyn Chang\n",
      "------\n",
      "You are a helpful assistant for a Computer Science university. You reply to students'questions about the courses that they can attend.\n",
      "<|im_end|>\n",
      "<|im_start|>user\n",
      "Who is the NLP teacher?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "The NLP teacher is Dr. Evelyn Chang. She is a professor in the NLP (Natural Language Processing) course and is responsible for guiding students through the course material.<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "messages = build_smoll_messages(\"Who is the NLP teacher?\", chunks, corpus_embedding)\n",
    "\n",
    "input_text=tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "inputs = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
    "outputs = model_generator.generate(inputs, max_new_tokens=100, temperature=0.01, top_p=0.9, do_sample=True)\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652d625b-19fe-40c6-9ce0-64f0679cb17d",
   "metadata": {},
   "source": [
    "# Groq generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1b3e8b13-e550-493a-971f-e31ad47c3bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os   \n",
    "load_dotenv()\n",
    "groq_api_key = os.getenv(\"API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "54d08068-9985-4d38-82cd-4e6a58ece916",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8b9fa7ce-fc3e-45eb-80d7-72b5ef06e913",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.OpenAI(\n",
    "    api_key=groq_api_key,\n",
    "    base_url=\"https://api.groq.com/openai/v1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "aee116f6-8847-4e1f-85b5-f22f0d3132bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What must I do to pass the NLP class?\"\n",
    "\n",
    "context_str = \"\\n\\n\".join(get_context(query, chunks, corpus_embedding))\n",
    "\n",
    "prompt = f\"\"\"Context information is below.\n",
    "---------------------\n",
    "{context_str}\n",
    "---------------------\n",
    "Given the context information and not prior knowledge, answer the query.\n",
    "If the answer is not in the context information, reply \"I cannot answer that question\".\n",
    "Query: {query}\n",
    "Answer:\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d2c25c",
   "metadata": {},
   "source": [
    "# Génération des fichiers de rendu\n",
    "\n",
    "## Informations sur les chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c8b1d22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STATISTIQUES DES CHUNKS\n",
      "============================================================\n",
      "\n",
      "Nombre total de chunks : 98\n",
      "\n",
      "Taille des chunks (en caractères) :\n",
      "  - Minimum : 71 caractères\n",
      "  - Maximum : 608 caractères\n",
      "  - Moyenne : 226.24 caractères\n",
      "  - Médiane : 208 caractères\n",
      "\n",
      "Dimension des embeddings : 768\n",
      "Forme du corpus_embedding : (98, 768)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Afficher les statistiques sur les chunks\n",
    "import json\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"STATISTIQUES DES CHUNKS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nNombre total de chunks : {len(chunks)}\")\n",
    "print(f\"\\nTaille des chunks (en caractères) :\")\n",
    "print(f\"  - Minimum : {min(len(chunk) for chunk in chunks)} caractères\")\n",
    "print(f\"  - Maximum : {max(len(chunk) for chunk in chunks)} caractères\")\n",
    "print(f\"  - Moyenne : {sum(len(chunk) for chunk in chunks) / len(chunks):.2f} caractères\")\n",
    "print(f\"  - Médiane : {sorted([len(chunk) for chunk in chunks])[len(chunks)//2]} caractères\")\n",
    "\n",
    "print(f\"\\nDimension des embeddings : {corpus_embedding.shape[1]}\")\n",
    "print(f\"Forme du corpus_embedding : {corpus_embedding.shape}\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36f19bc",
   "metadata": {},
   "source": [
    "## Exemples de chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7bf36f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemples de chunks (3 premiers) :\n",
      "============================================================\n",
      "\n",
      "[Chunk 1] Taille: 125 caractères\n",
      "Contenu: Introduction to Cybersecurity: Principles and Practices  : # Title: Introduction to Cybersecurity: Principles and Practices  \n",
      "------------------------------------------------------------\n",
      "\n",
      "[Chunk 2] Taille: 96 caractères\n",
      "Contenu: Introduction to Cybersecurity: Principles and Practices  : **Teacher:** Professor Lydia Carter  \n",
      "------------------------------------------------------------\n",
      "\n",
      "[Chunk 3] Taille: 540 caractères\n",
      "Contenu: Introduction to Cybersecurity: Principles and Practices  : **Description:**  \n",
      "This course introduces the fundamentals of cybersecurity, focusing on protecting systems, networks, and data from cyber th...\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Afficher quelques exemples de chunks\n",
    "print(\"Exemples de chunks (3 premiers) :\")\n",
    "print(\"=\"*60)\n",
    "for i, chunk in enumerate(chunks[:3]):\n",
    "    print(f\"\\n[Chunk {i+1}] Taille: {len(chunk)} caractères\")\n",
    "    print(f\"Contenu: {chunk[:200]}...\" if len(chunk) > 200 else f\"Contenu: {chunk}\")\n",
    "    print(\"-\"*60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2f4e51",
   "metadata": {},
   "source": [
    "## Génération du CSV chunks avec embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "28b0debc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame créé avec 98 chunks\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Introduction to Cybersecurity: Principles and ...</td>\n",
       "      <td>[0.01177978515625, 0.00832366943359375, -0.014...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Introduction to Cybersecurity: Principles and ...</td>\n",
       "      <td>[0.0369873046875, -0.01201629638671875, -0.010...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Introduction to Cybersecurity: Principles and ...</td>\n",
       "      <td>[0.0277099609375, -0.012054443359375, 0.001070...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Introduction to Cybersecurity: Principles and ...</td>\n",
       "      <td>[0.01399993896484375, -0.01212310791015625, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Introduction to Cybersecurity: Principles and ...</td>\n",
       "      <td>[0.021697998046875, -0.0242156982421875, -0.03...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               chunk  \\\n",
       "0  Introduction to Cybersecurity: Principles and ...   \n",
       "1  Introduction to Cybersecurity: Principles and ...   \n",
       "2  Introduction to Cybersecurity: Principles and ...   \n",
       "3  Introduction to Cybersecurity: Principles and ...   \n",
       "4  Introduction to Cybersecurity: Principles and ...   \n",
       "\n",
       "                                           embedding  \n",
       "0  [0.01177978515625, 0.00832366943359375, -0.014...  \n",
       "1  [0.0369873046875, -0.01201629638671875, -0.010...  \n",
       "2  [0.0277099609375, -0.012054443359375, 0.001070...  \n",
       "3  [0.01399993896484375, -0.01212310791015625, -0...  \n",
       "4  [0.021697998046875, -0.0242156982421875, -0.03...  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Créer un DataFrame avec les chunks et leurs embeddings\n",
    "# L'embedding doit être au format JSON (liste de floats)\n",
    "\n",
    "chunks_data = []\n",
    "for i, (chunk, embedding) in enumerate(zip(chunks, corpus_embedding)):\n",
    "    chunks_data.append({\n",
    "        'chunk': chunk,\n",
    "        'embedding': json.dumps(embedding.tolist())  # Convertir en JSON\n",
    "    })\n",
    "\n",
    "df_chunks = pd.DataFrame(chunks_data)\n",
    "print(f\"DataFrame créé avec {len(df_chunks)} chunks\")\n",
    "df_chunks.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8f1caa47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ CSV des chunks sauvegardé : ../data/processed/chunks_embeddings.csv\n",
      "  Nombre de lignes : 98\n"
     ]
    }
   ],
   "source": [
    "# Sauvegarder le CSV des chunks\n",
    "output_chunks_path = Path(\"../data/processed/chunks_embeddings.csv\")\n",
    "df_chunks.to_csv(output_chunks_path, index=False)\n",
    "print(f\"✓ CSV des chunks sauvegardé : {output_chunks_path}\")\n",
    "print(f\"  Nombre de lignes : {len(df_chunks)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b154ad17",
   "metadata": {},
   "source": [
    "## Génération du CSV questions avec embeddings et réponses RAG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "229b45a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de questions à traiter : 27\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Who is the reinforcement learning teacher?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In what class will I learn game A.I.?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What are the requirements to build a game A.I.?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How will I validate the reinforcement learning...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which class will teach me to build a chatbot?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What are the requirements to build a chatbot?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What models do we use for text A.I.?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What are the applications of NLP?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What class will teach me to program a Arduino?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What IoT system can I build in class</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question\n",
       "0         Who is the reinforcement learning teacher?\n",
       "1              In what class will I learn game A.I.?\n",
       "2    What are the requirements to build a game A.I.?\n",
       "3  How will I validate the reinforcement learning...\n",
       "4      Which class will teach me to build a chatbot?\n",
       "5      What are the requirements to build a chatbot?\n",
       "6               What models do we use for text A.I.?\n",
       "7                  What are the applications of NLP?\n",
       "8     What class will teach me to program a Arduino?\n",
       "9               What IoT system can I build in class"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Charger les questions depuis question.csv\n",
    "df_questions = pd.read_csv(path / \"question.csv\")\n",
    "# Retirer les lignes vides\n",
    "df_questions = df_questions.dropna(subset=['question'])\n",
    "df_questions = df_questions[df_questions['question'].str.strip() != '']\n",
    "\n",
    "print(f\"Nombre de questions à traiter : {len(df_questions)}\")\n",
    "df_questions.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c68e03c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour générer une réponse RAG avec Groq\n",
    "def generate_rag_answer(query, chunks, corpus_embedding, client):\n",
    "    \"\"\"\n",
    "    Génère une réponse RAG pour une question donnée.\n",
    "    \n",
    "    Paramètres:\n",
    "    - query: la question posée\n",
    "    - chunks: liste des chunks de texte\n",
    "    - corpus_embedding: embeddings des chunks\n",
    "    - client: client OpenAI/Groq\n",
    "    \n",
    "    Retourne:\n",
    "    - La réponse générée par le modèle\n",
    "    \"\"\"\n",
    "    # Récupérer le contexte pertinent\n",
    "    context_str = \"\\n\\n\".join(get_context(query, chunks, corpus_embedding))\n",
    "    \n",
    "    # Construire le prompt\n",
    "    prompt = f\"\"\"Context information is below.\n",
    "---------------------\n",
    "{context_str}\n",
    "---------------------\n",
    "Given the context information and not prior knowledge, answer the query.\n",
    "If the answer is not in the context information, reply \"I cannot answer that question\".\n",
    "Query: {query}\n",
    "Answer:\"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Appeler l'API Groq\n",
    "        res = client.chat.completions.create(\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            model=\"openai/gpt-oss-20b\",\n",
    "        )\n",
    "        return res.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la génération pour '{query}': {e}\")\n",
    "        return f\"Erreur: {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e087f6e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Génération des embeddings pour les questions...\n",
      "✓ Embeddings générés pour 27 questions\n",
      "\n",
      "Génération des réponses RAG...\n",
      "  [1/27] Traitement de: Who is the reinforcement learning teacher?...\n",
      "  [2/27] Traitement de: In what class will I learn game A.I.?...\n",
      "  [3/27] Traitement de: What are the requirements to build a game A.I.?...\n",
      "  [4/27] Traitement de: How will I validate the reinforcement learning class?...\n",
      "  [5/27] Traitement de: Which class will teach me to build a chatbot?...\n",
      "  [6/27] Traitement de: What are the requirements to build a chatbot?...\n",
      "  [7/27] Traitement de: What models do we use for text A.I.?...\n",
      "  [8/27] Traitement de: What are the applications of NLP?...\n",
      "  [9/27] Traitement de: What class will teach me to program a Arduino?...\n",
      "  [10/27] Traitement de: What IoT system can I build in class...\n",
      "  [11/27] Traitement de: What are the applications of IoT?...\n",
      "  [12/27] Traitement de: How do I validate the IoT class?...\n",
      "  [13/27] Traitement de: What language must I know to code embedded systems...\n",
      "  [14/27] Traitement de: Which class will have lessons on hardware...\n",
      "  [15/27] Traitement de: What are the specific issues I see in embedded systems?...\n",
      "  [16/27] Traitement de: What can I build in the embedded system class?...\n",
      "  [17/27] Traitement de: What class will teach me deployment procedures?...\n",
      "  [18/27] Traitement de: What technology are taught to deploy solutions?...\n",
      "  [19/27] Traitement de: What does \"CI/CD\" means?...\n",
      "  [20/27] Traitement de: What tools are recommended for logging?...\n",
      "  [21/27] Traitement de: What cyber attacks are there?...\n",
      "  [22/27] Traitement de: What are the prerequisistes for the security class?...\n",
      "  [23/27] Traitement de: What class will teach me about hacking...\n",
      "  [24/27] Traitement de: What database systems are taught?...\n",
      "  [25/27] Traitement de: What tools do we use to handle Big Data?...\n",
      "  [26/27] Traitement de: What should I know to manage a database?...\n",
      "  [27/27] Traitement de: What to do to perfectly cook pasta?...\n",
      "✓ 27 réponses générées\n"
     ]
    }
   ],
   "source": [
    "# Générer les embeddings et réponses pour toutes les questions\n",
    "questions_list = df_questions['question'].tolist()\n",
    "\n",
    "# Générer les embeddings pour toutes les questions\n",
    "print(\"Génération des embeddings pour les questions...\")\n",
    "questions_embeddings = model.encode(questions_list)\n",
    "print(f\"✓ Embeddings générés pour {len(questions_list)} questions\")\n",
    "\n",
    "# Générer les réponses RAG pour chaque question\n",
    "print(\"\\nGénération des réponses RAG...\")\n",
    "rag_answers = []\n",
    "for i, question in enumerate(questions_list):\n",
    "    print(f\"  [{i+1}/{len(questions_list)}] Traitement de: {question[:60]}...\")\n",
    "    answer = generate_rag_answer(question, chunks, corpus_embedding, client)\n",
    "    rag_answers.append(answer)\n",
    "\n",
    "print(f\"✓ {len(rag_answers)} réponses générées\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3edeaa6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame créé avec 27 questions\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>embedding</th>\n",
       "      <th>rag_reply</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Who is the reinforcement learning teacher?</td>\n",
       "      <td>[-0.009368896484375, -0.0645751953125, -0.0037...</td>\n",
       "      <td>The reinforcement learning teacher is Dr. Arju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In what class will I learn game A.I.?</td>\n",
       "      <td>[-0.02490234375, 0.013763427734375, 0.04547119...</td>\n",
       "      <td>You’ll learn game AI in the **Foundations of R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What are the requirements to build a game A.I.?</td>\n",
       "      <td>[-0.0035305023193359375, 0.0216064453125, 0.04...</td>\n",
       "      <td>I cannot answer that question.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How will I validate the reinforcement learning...</td>\n",
       "      <td>[0.0026454925537109375, -0.0254974365234375, -...</td>\n",
       "      <td>I cannot answer that question.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which class will teach me to build a chatbot?</td>\n",
       "      <td>[0.0225677490234375, -0.0487060546875, 0.00802...</td>\n",
       "      <td>The **Applications of NLP** class (section 5) ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0         Who is the reinforcement learning teacher?   \n",
       "1              In what class will I learn game A.I.?   \n",
       "2    What are the requirements to build a game A.I.?   \n",
       "3  How will I validate the reinforcement learning...   \n",
       "4      Which class will teach me to build a chatbot?   \n",
       "\n",
       "                                           embedding  \\\n",
       "0  [-0.009368896484375, -0.0645751953125, -0.0037...   \n",
       "1  [-0.02490234375, 0.013763427734375, 0.04547119...   \n",
       "2  [-0.0035305023193359375, 0.0216064453125, 0.04...   \n",
       "3  [0.0026454925537109375, -0.0254974365234375, -...   \n",
       "4  [0.0225677490234375, -0.0487060546875, 0.00802...   \n",
       "\n",
       "                                           rag_reply  \n",
       "0  The reinforcement learning teacher is Dr. Arju...  \n",
       "1  You’ll learn game AI in the **Foundations of R...  \n",
       "2                     I cannot answer that question.  \n",
       "3                     I cannot answer that question.  \n",
       "4  The **Applications of NLP** class (section 5) ...  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Créer le DataFrame avec questions, embeddings et réponses\n",
    "questions_data = []\n",
    "for question, embedding, answer in zip(questions_list, questions_embeddings, rag_answers):\n",
    "    questions_data.append({\n",
    "        'question': question,\n",
    "        'embedding': json.dumps(embedding.tolist()),  # Convertir en JSON\n",
    "        'rag_reply': answer\n",
    "    })\n",
    "\n",
    "df_questions_output = pd.DataFrame(questions_data)\n",
    "print(f\"DataFrame créé avec {len(df_questions_output)} questions\")\n",
    "df_questions_output.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "81880659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ CSV des questions sauvegardé : ../data/processed/questions_embeddings_answers.csv\n",
      "  Nombre de lignes : 27\n"
     ]
    }
   ],
   "source": [
    "# Sauvegarder le CSV des questions\n",
    "output_questions_path = Path(\"../data/processed/questions_embeddings_answers.csv\")\n",
    "df_questions_output.to_csv(output_questions_path, index=False)\n",
    "print(f\"✓ CSV des questions sauvegardé : {output_questions_path}\")\n",
    "print(f\"  Nombre de lignes : {len(df_questions_output)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fcab8a",
   "metadata": {},
   "source": [
    "## Vérification des fichiers générés\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c184311a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vérification du format des embeddings...\n",
      "\n",
      "1. Test de chargement d'un embedding de chunk:\n",
      "   ✓ Type: <class 'list'>\n",
      "   ✓ Longueur: 768\n",
      "   ✓ Premier élément: 0.01177978515625 (type: <class 'float'>)\n",
      "\n",
      "2. Test de chargement d'un embedding de question:\n",
      "   ✓ Type: <class 'list'>\n",
      "   ✓ Longueur: 768\n",
      "   ✓ Premier élément: -0.009368896484375 (type: <class 'float'>)\n",
      "\n",
      "✓ Les embeddings sont au bon format !\n"
     ]
    }
   ],
   "source": [
    "# Vérifier que les embeddings peuvent être rechargés correctement\n",
    "print(\"Vérification du format des embeddings...\")\n",
    "print(\"\\n1. Test de chargement d'un embedding de chunk:\")\n",
    "test_chunk_embedding = json.loads(df_chunks.iloc[0]['embedding'])\n",
    "print(f\"   ✓ Type: {type(test_chunk_embedding)}\")\n",
    "print(f\"   ✓ Longueur: {len(test_chunk_embedding)}\")\n",
    "print(f\"   ✓ Premier élément: {test_chunk_embedding[0]} (type: {type(test_chunk_embedding[0])})\")\n",
    "\n",
    "print(\"\\n2. Test de chargement d'un embedding de question:\")\n",
    "test_question_embedding = json.loads(df_questions_output.iloc[0]['embedding'])\n",
    "print(f\"   ✓ Type: {type(test_question_embedding)}\")\n",
    "print(f\"   ✓ Longueur: {len(test_question_embedding)}\")\n",
    "print(f\"   ✓ Premier élément: {test_question_embedding[0]} (type: {type(test_question_embedding[0])})\")\n",
    "\n",
    "print(\"\\n✓ Les embeddings sont au bon format !\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4657a7",
   "metadata": {},
   "source": [
    "## Aperçu des réponses générées\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ef873e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemples de questions et réponses générées:\n",
      "================================================================================\n",
      "\n",
      "[Question 1]\n",
      "Q: Who is the reinforcement learning teacher?\n",
      "R: The reinforcement learning teacher is Dr. Arjun Patel.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Question 2]\n",
      "Q: In what class will I learn game A.I.?\n",
      "R: You’ll learn game AI in the **Foundations of Reinforcement Learning** class.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Question 3]\n",
      "Q: What are the requirements to build a game A.I.?\n",
      "R: I cannot answer that question.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Question 4]\n",
      "Q: How will I validate the reinforcement learning class?\n",
      "R: I cannot answer that question.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Question 5]\n",
      "Q: Which class will teach me to build a chatbot?\n",
      "R: The **Applications of NLP** class (section 5) covers chatbots and conversational agents, and the **Final Project** gives you the hands‑on opportunity to build a chatbot.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Afficher quelques exemples de questions et réponses\n",
    "print(\"Exemples de questions et réponses générées:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for i in range(min(5, len(df_questions_output))):\n",
    "    row = df_questions_output.iloc[i]\n",
    "    print(f\"\\n[Question {i+1}]\")\n",
    "    print(f\"Q: {row['question']}\")\n",
    "    print(f\"R: {row['rag_reply']}\")\n",
    "    print(\"-\"*80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ad576c",
   "metadata": {},
   "source": [
    "## Résumé final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9e8db66a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "RÉSUMÉ DU RAG\n",
      "================================================================================\n",
      "\n",
      " CONFIGURATION DU CHUNKING:\n",
      "   • Méthode: Split par paragraphes (\\n\\n) avec ajout du titre\n",
      "   • Nombre de chunks: 98\n",
      "   • Taille moyenne: 226 caractères\n",
      "   • Taille min/max: 71/608 caractères\n",
      "\n",
      " EMBEDDING:\n",
      "   • Modèle: BAAI/bge-base-en-v1.5\n",
      "   • Dimension: 768\n",
      "   • Instruction de requête: 'Represent this sentence for searching relevant passages:'\n",
      "\n",
      " GÉNÉRATION:\n",
      "   • Modèle: openai/gpt-oss-20b (via Groq)\n",
      "   • Nombre de chunks récupérés: 5 (top-5)\n",
      "   • Stratégie: Contexte + prompt avec instruction de ne répondre que selon le contexte\n",
      "\n",
      " FICHIERS GÉNÉRÉS:\n",
      "   • ../data/processed/chunks_embeddings.csv\n",
      "     → 98 chunks avec embeddings\n",
      "   • ../data/processed/questions_embeddings_answers.csv\n",
      "     → 27 questions avec embeddings et réponses\n",
      "\n",
      " RAG complet généré avec succès !\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Résumé final du RAG\n",
    "print(\"=\"*80)\n",
    "print(\"RÉSUMÉ DU RAG\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n CONFIGURATION DU CHUNKING:\")\n",
    "print(f\"   • Méthode: Split par paragraphes (\\\\n\\\\n) avec ajout du titre\")\n",
    "print(f\"   • Nombre de chunks: {len(chunks)}\")\n",
    "print(f\"   • Taille moyenne: {sum(len(chunk) for chunk in chunks) / len(chunks):.0f} caractères\")\n",
    "print(f\"   • Taille min/max: {min(len(chunk) for chunk in chunks)}/{max(len(chunk) for chunk in chunks)} caractères\")\n",
    "\n",
    "print(\"\\n EMBEDDING:\")\n",
    "print(f\"   • Modèle: BAAI/bge-base-en-v1.5\")\n",
    "print(f\"   • Dimension: {corpus_embedding.shape[1]}\")\n",
    "print(f\"   • Instruction de requête: 'Represent this sentence for searching relevant passages:'\")\n",
    "\n",
    "print(\"\\n GÉNÉRATION:\")\n",
    "print(f\"   • Modèle: openai/gpt-oss-20b (via Groq)\")\n",
    "print(f\"   • Nombre de chunks récupérés: 5 (top-5)\")\n",
    "print(f\"   • Stratégie: Contexte + prompt avec instruction de ne répondre que selon le contexte\")\n",
    "\n",
    "print(\"\\n FICHIERS GÉNÉRÉS:\")\n",
    "print(f\"   • {output_chunks_path}\")\n",
    "print(f\"     → {len(df_chunks)} chunks avec embeddings\")\n",
    "print(f\"   • {output_questions_path}\")\n",
    "print(f\"     → {len(df_questions_output)} questions avec embeddings et réponses\")\n",
    "\n",
    "print(\"\\n RAG complet généré avec succès !\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ec9d5f32-15dd-4f27-8788-018657f8a2dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res = client.chat.completions.create(                                            \n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],                              \n",
    "    model=\"openai/gpt-oss-20b\",                                                                 \n",
    ")                                                                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "af821664-0401-4715-adc4-fb62e46dc4d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To pass the NLP course, you need to:\\n\\n1. **Complete all weekly coding assignments** – they count for 30\\u202f% of your grade.  \\n2. **Do well on the midterm exam** – worth 20\\u202f% of the final grade.  \\n3. **Finish the final project** (an end‑to‑end NLP application) – this is the largest component, accounting for 30\\u202f%.  \\n4. **Participate actively** in class discussions and code reviews – this contributes 20\\u202f% of the grade.  \\n\\nIn addition, make sure you meet the prerequisites (Python programming, basic linear algebra and probability, and prior completion of an introductory ML course). Performing satisfactorily across all four areas will earn you a passing grade.'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc86e026-afa4-4a72-ae2b-1268573e12c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
